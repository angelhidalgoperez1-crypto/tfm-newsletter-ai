# AI-powered Newsletter Generator

Trabajo Fin de MÃ¡ster â€“ End-to-end NLP pipeline for automatic curation of AI & Tech news.

## ğŸ“Œ Project overview

This project implements a complete pipeline to automatically:
- Collect technology and AI-related news from multiple sources
- Represent articles semantically using multilingual embeddings
- Group articles into thematic clusters
- Rank and curate the most relevant content
- Generate a structured newsletter-style output

The objective is to demonstrate how Natural Language Processing techniques can be applied in a realistic, business-oriented scenario, with an emphasis on interpretability and productization.

---

## ğŸ§± Project structure

tfm_newsletter_ai/
â”œâ”€â”€ config/ # Paths and configuration files
â”œâ”€â”€ data/ # Data directories (ignored in git)
â”œâ”€â”€ nlp/ # NLP modules: embeddings, clustering, scoring
â”œâ”€â”€ scraping/ # Web scrapers and normalization logic
â”œâ”€â”€ notebooks/ # End-to-end analysis notebooks
â”œâ”€â”€ scripts/ # Execution scripts for pipeline steps
â”œâ”€â”€ output/ # Generated diagnostics and newsletter outputs
â”œâ”€â”€ models/ # Saved models (ignored in git)
â””â”€â”€ README.md


---

## ğŸ”„ Pipeline description

1. **Data collection**  
   Articles are scraped from multiple online sources using custom scrapers.

2. **Text preprocessing**  
   Content is normalized and cleaned to ensure consistency across sources and languages.

3. **Semantic embeddings**  
   Articles are transformed into vector representations using Sentence-Transformers.

4. **Clustering**  
   Articles are grouped into thematic clusters using unsupervised learning techniques.

5. **Interpretability**  
   Clusters are interpreted using TF-IDF to extract representative keywords.

6. **Scoring & ranking**  
   Articles are ranked based on relevance, novelty, recency, and source reliability.

7. **Newsletter generation**  
   The final output is a curated, structured newsletter ready for consumption.

---

## âš™ï¸ Configuration

Main parameters (models, clustering options, scoring weights, etc.) are defined in YAML configuration files located in the `config/` directory.

This allows easy experimentation and reproducibility without modifying code.

---

## ğŸš€ How to run the project

1. Clone the repository:
```bash

git clone https://github.com/angelhidalgoperez1-crypto/tfm-newsletter-ai.git

2. Install dependencies (recommended: conda environment):

pip install -r requirements.txt

3. Run the main notebook:

notebooks/definitive.ipynb


ğŸ“ Data availability

Due to size constraints, datasets and intermediate artifacts are not included in the repository.

All data can be regenerated by running the scraping and preprocessing pipeline provided in this project.

ğŸ§© Productization perspective

The project has been designed with production usage in mind:

Modular architecture

Config-driven behavior

Clear separation between data, logic, and outputs

The pipeline can be adapted into an internal business application where new articles are periodically ingested and automatically curated.
