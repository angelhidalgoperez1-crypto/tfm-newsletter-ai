{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a238cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\Angel\\OneDrive - Universidad Complutense de Madrid (UCM)\\Documentos\\MASTER\\99_tfm\\tfm_newsletter_ai\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = r\"C:\\Users\\Angel\\OneDrive - Universidad Complutense de Madrid (UCM)\\Documentos\\MASTER\\99_tfm\\tfm_newsletter_ai\"\n",
    "\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraping.sources.scraper_xataka import XatakaScraper\n",
    "import pandas as pd\n",
    "\n",
    "scraper = XatakaScraper()\n",
    "\n",
    "links = scraper.get_article_links()\n",
    "print(f\"Artículos encontrados: {len(links)}\")\n",
    "\n",
    "articles = []\n",
    "for url in links[:5]:  # solo 5 para pruebas\n",
    "    article = scraper.scrape_article(url)\n",
    "    if article:\n",
    "        articles.append(article)\n",
    "\n",
    "df = pd.DataFrame(articles)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2392ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraping.sources.scraper_xataka import XatakaScraper\n",
    "from scraping.sources.scraper_openai import OpenAIScraper\n",
    "import pandas as pd\n",
    "\n",
    "scrapers = [\n",
    "    XatakaScraper(),\n",
    "    OpenAIScraper()\n",
    "]\n",
    "\n",
    "articles = []\n",
    "\n",
    "for scraper in scrapers:\n",
    "    links = scraper.get_article_links()\n",
    "    for url in links[:3]:  # pocos para test\n",
    "        article = scraper.scrape_article(url)\n",
    "        if article:\n",
    "            articles.append(article)\n",
    "\n",
    "df = pd.DataFrame(articles)\n",
    "df[[\"source\", \"title\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9818e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraping.sources.scraper_xataka import XatakaScraper\n",
    "from scraping.sources.scraper_huggingface import HuggingFaceScraper\n",
    "\n",
    "scrapers = [\n",
    "    XatakaScraper(),\n",
    "    HuggingFaceScraper()\n",
    "]\n",
    "\n",
    "articles = []\n",
    "\n",
    "for scraper in scrapers:\n",
    "    links = scraper.get_article_links()\n",
    "    for url in links[:3]:  # pocos para test\n",
    "        article = scraper.scrape_article(url)\n",
    "        if article:\n",
    "            articles.append(article)\n",
    "\n",
    "df = pd.DataFrame(articles)\n",
    "df[[\"source\", \"title\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760aaf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraping.normalization import normalize_article\n",
    "\n",
    "normalized_articles = [\n",
    "    normalize_article(a) for a in articles\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(normalized_articles)\n",
    "df[[\"source\", \"word_count\", \"language\", \"is_valid\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df[df[\"is_valid\"]].copy()\n",
    "df_clean.shape\n",
    "\n",
    "output_path = \"data/raw/articles_normalized.csv\"\n",
    "\n",
    "df_clean.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd1973",
   "metadata": {},
   "source": [
    "# Más fuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395bc159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[TechCrunch] HTTP error en https://techcrunch.com/tag/robotics/page/31/: 404 Client Error: Not Found for url: https://techcrunch.com/tag/robotics/page/31/\n",
      "WARNING:root:[AWS Blog] HTTP error en https://aws.amazon.com/es/blogs/infrastructure-and-automation/page/11/: 404 Client Error:  for url: https://aws.amazon.com/es/blogs/infrastructure-and-automation/page/11/\n",
      "WARNING:root:[AWS] Fallo en https://aws.amazon.com/es/blogs/infrastructure-and-automation/page/11/\n",
      "WARNING:root:[AWS Blog] HTTP error en https://aws.amazon.com/es/blogs/iot/page/37/: 404 Client Error:  for url: https://aws.amazon.com/es/blogs/iot/page/37/\n",
      "WARNING:root:[AWS] Fallo en https://aws.amazon.com/es/blogs/iot/page/37/\n",
      "WARNING:root:[AWS Blog] HTTP error en https://aws.amazon.com/blogs/machine-learning/build-a-domain%E2%80%90aware-data-preprocessing-pipeline-a-multi%E2%80%90agent-collaboration-approach/: 404 Client Error:  for url: https://aws.amazon.com/es/blogs/machine-learning/build-a-domain%25E2%2580%2590aware-data-preprocessing-pipeline-a-multi%25E2%2580%2590agent-collaboration-approach/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1193"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scraping.sources.scraper_xataka import XatakaScraper\n",
    "from scraping.sources.scraper_huggingface import HuggingFaceScraper\n",
    "from scraping.sources.scraper_techcrunch import TechCrunchScraper\n",
    "from scraping.sources.scraper_aws import AWSScraper\n",
    "from scraping.sources.scraper_wired import WiredScraper\n",
    "from scraping.sources.scraper_microsoft import MicrosoftNewsScraper\n",
    "from scraping.sources.scraper_aibusiness import AIBusinessScraper\n",
    "\n",
    "scrapers = [\n",
    "    XatakaScraper(),\n",
    "    # HuggingFaceScraper(max_pages=3),\n",
    "    TechCrunchScraper(max_pages=50),\n",
    "    AWSScraper(max_pages=50,\n",
    "               blogs=[\"machine-learning\",\n",
    "                    \"infrastructure-and-automation\",\n",
    "                    \"iot\",\n",
    "                    \"big-data\"\n",
    "                    ]\n",
    "            ),\n",
    "    WiredScraper(max_pages=50)\n",
    "    # MicrosoftNewsScraper(),\n",
    "    # AIBusinessScraper(max_pages=2)\n",
    "]\n",
    "\n",
    "articles = []\n",
    "\n",
    "for scraper in scrapers:\n",
    "    links = scraper.get_article_links()\n",
    "    for url in links:\n",
    "        article = scraper.scrape_article(url)\n",
    "        if article:\n",
    "            articles.append(article)\n",
    "\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ae1d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Angel\\anaconda3\\Lib\\html\\parser.py:189: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    }
   ],
   "source": [
    "from scraping.sources.scraper_microsoft import MicrosoftNewsScraper\n",
    "ms = MicrosoftNewsScraper(max_pages=2)\n",
    "links = ms.get_article_links()\n",
    "print(len(links))\n",
    "print(links[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import logging\n",
    "from scraping.scraper_base import BaseScraper\n",
    "\n",
    "class TechCrunchScraper(BaseScraper):\n",
    "\n",
    "    def __init__(self, tags=None):\n",
    "        super().__init__(\"TechCrunch\")\n",
    "\n",
    "        self.base_feed_url = \"https://techcrunch.com/tag\"\n",
    "        self.tags = tags or [\n",
    "            \"artificial-intelligence\",\n",
    "            \"cloud-computing\",\n",
    "            \"robotics\"\n",
    "        ]\n",
    "\n",
    "    def get_article_links(self):\n",
    "        links = set()\n",
    "\n",
    "        for tag in self.tags:\n",
    "            feed_url = f\"{self.base_feed_url}/{tag}/feed/\"\n",
    "            logging.info(f\"[TechCrunch RSS] Leyendo {feed_url}\")\n",
    "\n",
    "            feed = feedparser.parse(feed_url)\n",
    "\n",
    "            for entry in feed.entries:\n",
    "                if \"link\" in entry:\n",
    "                    links.add(entry.link)\n",
    "\n",
    "        logging.info(f\"[TechCrunch RSS] Total links: {len(links)}\")\n",
    "        return list(links)\n",
    "\n",
    "    def scrape_article(self, url):\n",
    "        soup = self.get_soup(url)\n",
    "        if soup is None:\n",
    "            return None\n",
    "\n",
    "        title = soup.find(\"h1\")\n",
    "        paragraphs = soup.select(\"div.article-content p\")\n",
    "\n",
    "        if not title or not paragraphs:\n",
    "            return None\n",
    "\n",
    "        return self.build_article(\n",
    "            url=url,\n",
    "            title=title.get_text(strip=True),\n",
    "            content=self.clean_text(paragraphs)\n",
    "        )\n",
    "\n",
    "\n",
    "techcrunch = TechCrunchScraper(\n",
    "    tags=[\n",
    "        \"artificial-intelligence\",\n",
    "        \"cloud-computing\",\n",
    "        \"robotics\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "links = techcrunch.get_article_links()\n",
    "print(len(links))\n",
    "print(links[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae9353cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "['https://techcrunch.com/2026/01/13/ai-drug-discovery-startup-converge-bio-pulls-in-25m-from-bessemer-and-execs-from-meta-openai-and-wiz/', 'https://techcrunch.com/2025/10/31/meta-bought-1-gw-of-solar-this-week/', 'https://techcrunch.com/2025/08/26/how-one-ai-startup-is-helping-rice-farmers-battle-climate-change/', 'https://techcrunch.com/2025/08/20/harvard-dropouts-to-launch-always-on-ai-smart-glasses-that-listen-and-record-every-conversation/', 'https://techcrunch.com/2025/08/20/meta-to-add-100-mw-of-solar-power-from-u-s-gear/']\n"
     ]
    }
   ],
   "source": [
    "from scraping.scraper_base import BaseScraper\n",
    "import logging\n",
    "\n",
    "class TechCrunchScraper(BaseScraper):\n",
    "\n",
    "    def __init__(self, tags=None, max_pages=20):\n",
    "        super().__init__(\"TechCrunch\")\n",
    "\n",
    "        self.tags = tags or [\n",
    "            \"artificial-intelligence\",\n",
    "            \"cloud-computing\",\n",
    "            \"robotics\"\n",
    "        ]\n",
    "\n",
    "        self.base_url = \"https://techcrunch.com/tag\"\n",
    "        self.max_pages = max_pages\n",
    "\n",
    "    def get_article_links(self):\n",
    "        links = []\n",
    "\n",
    "        for tag in self.tags:\n",
    "            for page in range(1, self.max_pages + 1):\n",
    "\n",
    "                if page == 1:\n",
    "                    url = f\"{self.base_url}/{tag}/\"\n",
    "                else:\n",
    "                    url = f\"{self.base_url}/{tag}/page/{page}/\"\n",
    "\n",
    "                soup = self.get_soup(url)\n",
    "                if soup is None:\n",
    "                    break\n",
    "\n",
    "                articles = soup.select(\"a.loop-card__title-link\")\n",
    "\n",
    "                if not articles:\n",
    "                    logging.info(f\"[TechCrunch] No más artículos en {tag}, page {page}\")\n",
    "                    break\n",
    "\n",
    "                for a in articles:\n",
    "                    href = a.get(\"href\")\n",
    "                    if href and href.startswith(\"https://techcrunch.com/\"):\n",
    "                        links.append(href)\n",
    "\n",
    "        return list(dict.fromkeys(links))\n",
    "\n",
    "    def scrape_article(self, url):\n",
    "        soup = self.get_soup(url)\n",
    "        if soup is None:\n",
    "            return None\n",
    "\n",
    "        title = soup.find(\"h1\")\n",
    "        paragraphs = soup.find_all(\"p\")\n",
    "\n",
    "        if not title or not paragraphs:\n",
    "            return None\n",
    "\n",
    "        return self.build_article(\n",
    "            url,\n",
    "            title.get_text(strip=True),\n",
    "            self.clean_text(paragraphs)\n",
    "        )\n",
    "\n",
    "    \n",
    "techcrunch = TechCrunchScraper(\n",
    "    max_pages=2\n",
    ")\n",
    "\n",
    "links = techcrunch.get_article_links()\n",
    "print(len(links))\n",
    "print(links[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf8877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraping.sources.scraper_techcrunch import TechCrunchScraper\n",
    "\n",
    "techcrunch = TechCrunchScraper(\n",
    "    max_pages=2\n",
    ")\n",
    "\n",
    "links = techcrunch.get_article_links()\n",
    "print(len(links))\n",
    "print(links[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "485c1c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 16 threads.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>scraping_date</th>\n",
       "      <th>content_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>language</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Xataka</td>\n",
       "      <td>https://www.xataka.com/empresas-y-economia/mas...</td>\n",
       "      <td>MásMóvil compra Sofiathinks, la startup sevill...</td>\n",
       "      <td>Desarrollar hardware en España no es tan habit...</td>\n",
       "      <td>2026-01-27 22:20:23.210903</td>\n",
       "      <td>2311</td>\n",
       "      <td>361</td>\n",
       "      <td>es</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xataka</td>\n",
       "      <td>https://www.xataka.com/robotica-e-ia/plan-indu...</td>\n",
       "      <td>El plan industrial de EEUU se desmorona porque...</td>\n",
       "      <td>La IA generativa es tontísima. Es la opinión d...</td>\n",
       "      <td>2026-01-27 22:20:23.439998</td>\n",
       "      <td>5739</td>\n",
       "      <td>983</td>\n",
       "      <td>es</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xataka</td>\n",
       "      <td>https://www.xataka.com/robotica-e-ia/no-coca-c...</td>\n",
       "      <td>No, Coca-Cola no está usando inteligencia arti...</td>\n",
       "      <td>La fiebre por la inteligencia artificial está ...</td>\n",
       "      <td>2026-01-27 22:20:24.200502</td>\n",
       "      <td>2926</td>\n",
       "      <td>489</td>\n",
       "      <td>es</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xataka</td>\n",
       "      <td>https://www.xataka.com/componentes/huawei-kunp...</td>\n",
       "      <td>Huawei Kunpeng 920: así es el SoC de 7 nm con ...</td>\n",
       "      <td>Huawei no se anda con «chiquitas»: según la ma...</td>\n",
       "      <td>2026-01-27 22:20:24.502001</td>\n",
       "      <td>3463</td>\n",
       "      <td>568</td>\n",
       "      <td>es</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xataka</td>\n",
       "      <td>https://www.xataka.com/empresas-y-economia/rea...</td>\n",
       "      <td>Realme más allá del smartphone: así quieren co...</td>\n",
       "      <td>Realme se ha convertido rápidamente en una mar...</td>\n",
       "      <td>2026-01-27 22:20:24.722319</td>\n",
       "      <td>3769</td>\n",
       "      <td>614</td>\n",
       "      <td>es</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6946</th>\n",
       "      <td>Wired ES</td>\n",
       "      <td>https://es.wired.com/articulos/deepseek-r1-pue...</td>\n",
       "      <td>El futuro es la eficiencia: DeepSeek R1 puede ...</td>\n",
       "      <td>La inteligencia artificial, o ya popularmente ...</td>\n",
       "      <td>2026-01-28 00:18:13.756831</td>\n",
       "      <td>6678</td>\n",
       "      <td>1101</td>\n",
       "      <td>es</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6947</th>\n",
       "      <td>Wired ES</td>\n",
       "      <td>https://es.wired.com/articulos/demanda-energet...</td>\n",
       "      <td>La demanda energética de la IA está fuera de c...</td>\n",
       "      <td>En estos momentos, es imposible ignorar la int...</td>\n",
       "      <td>2026-01-28 00:18:14.107712</td>\n",
       "      <td>10412</td>\n",
       "      <td>1670</td>\n",
       "      <td>es</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6948</th>\n",
       "      <td>Wired ES</td>\n",
       "      <td>https://es.wired.com/articulos/el-36-por-cient...</td>\n",
       "      <td>El 36% de las personas se sienten cómodas leye...</td>\n",
       "      <td>El uso de la inteligencia artificial (IA) en l...</td>\n",
       "      <td>2026-01-28 00:18:14.539258</td>\n",
       "      <td>5331</td>\n",
       "      <td>859</td>\n",
       "      <td>es</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6949</th>\n",
       "      <td>Wired ES</td>\n",
       "      <td>https://es.wired.com/articulos/x-lanza-oficial...</td>\n",
       "      <td>X lanza oficialmente Grok 3, su nuevo modelo d...</td>\n",
       "      <td>Tras muchos meses de espera, xAI, la empresa d...</td>\n",
       "      <td>2026-01-28 00:18:15.263931</td>\n",
       "      <td>3882</td>\n",
       "      <td>657</td>\n",
       "      <td>es</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6950</th>\n",
       "      <td>Wired ES</td>\n",
       "      <td>https://es.wired.com/articulos/rabbit-r1-arras...</td>\n",
       "      <td>El Rabbit R1 que arrasó en las ferias tecnológ...</td>\n",
       "      <td>El camino que conducía a la sede de Rabbit est...</td>\n",
       "      <td>2026-01-28 00:18:17.575284</td>\n",
       "      <td>9142</td>\n",
       "      <td>1569</td>\n",
       "      <td>es</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6951 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source                                                url  \\\n",
       "0       Xataka  https://www.xataka.com/empresas-y-economia/mas...   \n",
       "1       Xataka  https://www.xataka.com/robotica-e-ia/plan-indu...   \n",
       "2       Xataka  https://www.xataka.com/robotica-e-ia/no-coca-c...   \n",
       "3       Xataka  https://www.xataka.com/componentes/huawei-kunp...   \n",
       "4       Xataka  https://www.xataka.com/empresas-y-economia/rea...   \n",
       "...        ...                                                ...   \n",
       "6946  Wired ES  https://es.wired.com/articulos/deepseek-r1-pue...   \n",
       "6947  Wired ES  https://es.wired.com/articulos/demanda-energet...   \n",
       "6948  Wired ES  https://es.wired.com/articulos/el-36-por-cient...   \n",
       "6949  Wired ES  https://es.wired.com/articulos/x-lanza-oficial...   \n",
       "6950  Wired ES  https://es.wired.com/articulos/rabbit-r1-arras...   \n",
       "\n",
       "                                                  title  \\\n",
       "0     MásMóvil compra Sofiathinks, la startup sevill...   \n",
       "1     El plan industrial de EEUU se desmorona porque...   \n",
       "2     No, Coca-Cola no está usando inteligencia arti...   \n",
       "3     Huawei Kunpeng 920: así es el SoC de 7 nm con ...   \n",
       "4     Realme más allá del smartphone: así quieren co...   \n",
       "...                                                 ...   \n",
       "6946  El futuro es la eficiencia: DeepSeek R1 puede ...   \n",
       "6947  La demanda energética de la IA está fuera de c...   \n",
       "6948  El 36% de las personas se sienten cómodas leye...   \n",
       "6949  X lanza oficialmente Grok 3, su nuevo modelo d...   \n",
       "6950  El Rabbit R1 que arrasó en las ferias tecnológ...   \n",
       "\n",
       "                                                content  \\\n",
       "0     Desarrollar hardware en España no es tan habit...   \n",
       "1     La IA generativa es tontísima. Es la opinión d...   \n",
       "2     La fiebre por la inteligencia artificial está ...   \n",
       "3     Huawei no se anda con «chiquitas»: según la ma...   \n",
       "4     Realme se ha convertido rápidamente en una mar...   \n",
       "...                                                 ...   \n",
       "6946  La inteligencia artificial, o ya popularmente ...   \n",
       "6947  En estos momentos, es imposible ignorar la int...   \n",
       "6948  El uso de la inteligencia artificial (IA) en l...   \n",
       "6949  Tras muchos meses de espera, xAI, la empresa d...   \n",
       "6950  El camino que conducía a la sede de Rabbit est...   \n",
       "\n",
       "                  scraping_date  content_length  word_count language  is_valid  \n",
       "0    2026-01-27 22:20:23.210903            2311         361       es      True  \n",
       "1    2026-01-27 22:20:23.439998            5739         983       es      True  \n",
       "2    2026-01-27 22:20:24.200502            2926         489       es      True  \n",
       "3    2026-01-27 22:20:24.502001            3463         568       es      True  \n",
       "4    2026-01-27 22:20:24.722319            3769         614       es      True  \n",
       "...                         ...             ...         ...      ...       ...  \n",
       "6946 2026-01-28 00:18:13.756831            6678        1101       es      True  \n",
       "6947 2026-01-28 00:18:14.107712           10412        1670       es      True  \n",
       "6948 2026-01-28 00:18:14.539258            5331         859       es      True  \n",
       "6949 2026-01-28 00:18:15.263931            3882         657       es      True  \n",
       "6950 2026-01-28 00:18:17.575284            9142        1569       es      True  \n",
       "\n",
       "[6951 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scraping.normalization import normalize_article\n",
    "\n",
    "normalized_articles = [\n",
    "    normalize_article(a) for a in articles\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(normalized_articles)\n",
    "df[[\"source\", \"word_count\", \"language\", \"is_valid\"]]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eab232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scraping.normalization import normalize_article\n",
    "\n",
    "normalized_articles = [\n",
    "    normalize_article(a) for a in articles\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(normalized_articles)\n",
    "df[[\"source\", \"word_count\", \"language\", \"is_valid\"]]\n",
    "\n",
    "df_clean = df[df[\"is_valid\"]].copy()\n",
    "df_clean.shape\n",
    "\n",
    "output_path = \"data/raw/even_more_articles_normalized.csv\"\n",
    "\n",
    "df_clean.to_csv(output_path, index=False, sep=\";\")\n",
    "df_clean = pd.read_csv(output_path, sep=\";\")  # para verificar que se guarda bien\n",
    "df_clean.to_parquet(\"data/raw/even_more_articles_normalized.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7779dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5754, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config.paths import RAW_DATA_DIR\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    os.path.join(RAW_DATA_DIR, \"even_more_articles_normalized.csv\"),\n",
    "    sep=\";\"\n",
    ")\n",
    "\n",
    "df_filtered = df[df.source != \"Wired ES\"]\n",
    "\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "767da6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "AWS Blog      1447\n",
       "TechCrunch    3715\n",
       "Wired ES      1193\n",
       "Xataka         592\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"source\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a03bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "output_path = \"data/raw/even_more_articles_normalized.csv\"\n",
    "output_path = os.path.join(PROJECT_ROOT,\"data\",\"raw\",\"even_more_articles_normalized.csv\")\n",
    "\n",
    "df_clean = pandas.read_csv(output_path, sep=\";\")  # para verificar que se guarda bien\n",
    "# df_clean.to_parquet(\"data/raw/even_more_articles_normalized.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d4e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.iloc[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6479961f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PA' from 'config.paths' (C:\\Users\\Angel\\OneDrive - Universidad Complutense de Madrid (UCM)\\Documentos\\MASTER\\99_tfm\\tfm_newsletter_ai\\config\\paths.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpaths\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PA\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(PA)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'PA' from 'config.paths' (C:\\Users\\Angel\\OneDrive - Universidad Complutense de Madrid (UCM)\\Documentos\\MASTER\\99_tfm\\tfm_newsletter_ai\\config\\paths.py)"
     ]
    }
   ],
   "source": [
    "from config.paths import PA\n",
    "\n",
    "print(PA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3463b066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angel\\OneDrive - Universidad Complutense de Madrid (UCM)\\Documentos\\MASTER\\99_tfm\n"
     ]
    }
   ],
   "source": [
    "from config.paths import RAW_DATA_DIR\n",
    "print(RAW_DATA_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
